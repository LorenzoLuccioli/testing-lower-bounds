\chapter{Kullback-Leibler divergence}

\begin{definition}[Kullback-Leibler divergence]
  \label{def:KL}
  %\lean{}
  %\leanok
  %\uses{}
  Let $\mu, \nu$ be two measures on $\mathcal X$. The Kullback-Leibler divergence between $\mu$ and $\nu$ is
  \begin{align*}
  \KL(\mu, \nu) = \mu\left[\log \frac{d \mu}{d \nu}\right]
  \end{align*}
  if $x \mapsto \log \frac{d \mu}{d \nu}(x)$ is $\mu$-integrable and $+\infty$ otherwise.
\end{definition}

\begin{lemma}
  \label{lem:kl_eq_fDiv}
  %\lean{}
  %\leanok
  \uses{def:KL, def:fDiv}
  $\KL(\mu, \nu) = D_f(\mu, \nu)$ for $f: x \mapsto x \log x$ or, for probability measures, $f: x \mapsto x \log x - x + 1$.
\end{lemma}

\begin{proof}
Simple computation.
\end{proof}

\section{Properties inherited from f-divergences}

Since $\KL$ is an f-divergence, every inequality for f-divergences can be translated to $\KL$.

\section{Chain rule and tensorization}

\begin{theorem}[Chain rule, kernel version]
  \label{thm:kl_chain_rule}
  %\lean{}
  %\leanok
  \uses{def:KL}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ two Markov kernels.
  Then $\KL(\mu \otimes \kappa, \nu \otimes \eta) = \KL(\mu, \nu) + \KL(\kappa, \eta \mid \mu)$.
\end{theorem}

\begin{proof}
\end{proof}

\begin{theorem}[Chain rule, product version]
  \label{thm:kl_chain_rule_prod}
  %\lean{}
  %\leanok
  \uses{def:KL}
  Let $\mu, \nu$ be two measures on $\mathcal X \times \mathcal Y$, where $\mathcal Y$ is standard Borel.
  Then $\KL(\mu, \nu) = \KL(\mu_X, \nu_X) + \KL(\mu_{Y|X}, \nu_{Y|X} \mid \mu_X)$.
\end{theorem}

\begin{proof}
\uses{thm:kl_chain_rule}
Write $\mu = \mu_X \otimes \mu_{Y|X}$ and $\nu = \nu_X \otimes \nu_{Y|X}$, then use Theorem~\ref{thm:kl_chain_rule}.
\end{proof}

\section{Change of measure}

\begin{lemma}
  \label{lem:llr_change_measure}
  %\lean{}
  %\leanok
  %\uses{}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $E$ be an event on $\mathcal X$. Let $\beta \in \mathbb{R}$. Then
  \begin{align*}
  \nu(E) e^{\beta} \ge \mu(E) - \mu\left\{ \log\frac{d \mu}{d \nu} > \beta \right\} \: .
  \end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\nu(E)
&\ge \mu\left[\mathbb{I}(E) e^{- \log\frac{d \mu}{d \nu} }\right]
\\
&\ge \mu\left[\mathbb{I}\left(E \cap \left\{\log\frac{d \mu}{d \nu} \le \beta\right\}\right) e^{- \log\frac{d \mu}{d \nu} }\right]
\\
&\ge e^{- \beta}\mu\left(E \cap \left\{\log\frac{d \mu}{d \nu} \le \beta\right\}\right)
\\
&\ge e^{- \beta}\left( \mu(E) - \mu\left\{ \log\frac{d \mu}{d \nu} > \beta \right\} \right)
\: .
\end{align*}
\end{proof}

\begin{corollary}
  \label{cor:kl_change_measure}
  %\lean{}
  %\leanok
  \uses{def:KL}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $E$ be an event on $\mathcal X$. Let $\beta \in \mathbb{R}$. Then
  \begin{align*}
  \nu(E) e^{\KL(\mu, \nu) + \beta} \ge \mu(E) - \mu\left\{ \log\frac{d \mu}{d \nu} - \KL(\mu, \nu) > \beta \right\} \: .
  \end{align*}
\end{corollary}

\begin{proof}
\uses{lem:llr_change_measure}
Use Lemma~\ref{lem:llr_change_measure} with the choice $\KL(\mu, \nu) + \beta$ for $\beta$.
\end{proof}

