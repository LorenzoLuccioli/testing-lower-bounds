\chapter{Kullback-Leibler divergence}

\begin{definition}[Kullback-Leibler divergence]
  \label{def:KL}
  %\lean{}
  %\leanok
  %\uses{}
  Let $\mu, \nu$ be two measures on $\mathcal X$. The Kullback-Leibler divergence between $\mu$ and $\nu$ is
  \begin{align*}
  \KL(\mu, \nu) = \mu\left[\log \frac{d \mu}{d \nu}\right]
  \end{align*}
  if $x \mapsto \log \frac{d \mu}{d \nu}(x)$ is $\mu$-integrable and $+\infty$ otherwise.
\end{definition}

\begin{lemma}
  \label{lem:kl_eq_fDiv}
  %\lean{}
  %\leanok
  \uses{def:KL, def:fDiv}
  $\KL(\mu, \nu) = D_f(\mu, \nu)$ for $f: x \mapsto x \log x$ or $f: x \mapsto x \log x - x + 1$.
\end{lemma}

\begin{proof}
Simple computation.
\end{proof}

\begin{theorem}[Chain rule, kernel version]
  \label{thm:kl_chain_rule}
  %\lean{}
  %\leanok
  \uses{def:KL}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ two Markov kernels.
  Then $\KL(\mu \otimes \kappa, \nu \otimes \eta) = \KL(\mu, \nu) + \KL(\kappa, \eta \mid \mu)$.
\end{theorem}

\begin{proof}
\end{proof}

\begin{theorem}[Chain rule, product version]
  \label{thm:kl_chain_rule_prod}
  %\lean{}
  %\leanok
  \uses{def:KL}
  Let $\mu, \nu$ be two measures on $\mathcal X \times \mathcal Y$, where $\mathcal Y$ is standard Borel.
  Then $\KL(\mu, \nu) = \KL(\mu_X, \nu_X) + \KL(\mu_{Y|X}, \nu_{Y|X} \mid \mu_X)$.
\end{theorem}

\begin{proof}
\uses{thm:kl_chain_rule}
Write $\mu = \mu_X \otimes \mu_{Y|X}$ and $\nu = \nu_X \otimes \nu_{Y|X}$, then use Theorem~\ref{thm:kl_chain_rule}.
\end{proof}