\section{Jensen-Shannon divergence}

\begin{definition}[Jensen-Shannon divergence]
  \label{def:jensenShannon}
  %\lean{}
  %\leanok
  \uses{def:KL}
  The Jensen-Shannon divergence indexed by $\alpha \in (0,1)$ between two measures $\mu$ and $\nu$ is
  \begin{align*}
    \JS_\alpha(\mu, \nu) = \alpha \KL(\mu, \alpha \mu + (1 - \alpha)\nu) + (1 - \alpha) \KL(\nu, \alpha \mu + (1 - \alpha)\nu) \: .
  \end{align*}
\end{definition}


\begin{lemma}
  \label{lem:jensenShannon_eq_kl}
  %\lean{}
  %\leanok
  \uses{def:jensenShannon, def:KL}
  Let $\mu, \nu \in \mathcal P(\mathcal X)$ and let $\alpha \in (0, 1)$. Let $\pi_\alpha = (\alpha, 1 - \alpha) \in \mathcal P(\{0,1\})$ and let $P : \{0,1\} \rightsquigarrow \mathcal X$ be the kernel with $P(0) = \mu$ and $P(1) = \nu$. Then
  \begin{align*}
  \JS_\alpha(\mu, ¸\nu) = \KL(\pi_\alpha \otimes P, \pi_\alpha \times (P \circ \pi_\alpha)) \: .
  \end{align*}
\end{lemma}

\begin{proof}%\leanok
\uses{}

\end{proof}


\begin{lemma}
  \label{lem:jensenShannon_symm}
  %\lean{}
  %\leanok
  \uses{def:jensenShannon}
  For $\alpha \in (0,1)$ and $\mu, \nu \in \mathcal M(\mathcal X)$,
  \begin{align*}
  \JS_\alpha(\mu, \nu) = \JS_{1 - \alpha}(\nu, \mu) \: .
  \end{align*}
\end{lemma}

\begin{proof}%\leanok
\uses{}
Immediate from the definition.
\end{proof}


\begin{lemma}
  \label{lem:jensenShannon_eq_inf_add_kl}
  %\lean{}
  %\leanok
  \uses{def:jensenShannon, def:KL}
  Let $\mu, \nu \in \mathcal P(\mathcal X)$ and let $\alpha \in (0, 1)$. Then
  \begin{align*}
  \JS_\alpha(\mu, \nu) = \inf_{\xi \in \mathcal P(\mathcal X)}\left( \alpha \KL(\mu, \xi) + (1 - \alpha)\KL(\nu, \xi) \right) \: .
  \end{align*}
  The infimum is attained at $\xi = \alpha \mu + (1 - \alpha) \nu$.
\end{lemma}

\begin{proof}%\leanok
\uses{}

\end{proof}


\begin{lemma}
  \label{lem:jensenShannon_eq_inf_kl}
  %\lean{}
  %\leanok
  \uses{def:jensenShannon, def:KL}
  Let $\mu, \nu \in \mathcal P(\mathcal X)$ and let $\alpha \in (0, 1)$. Let $\pi_\alpha = (\alpha, 1 - \alpha) \in \mathcal P(\{0,1\})$ and let $P : \{0,1\} \rightsquigarrow \mathcal X$ be the kernel with $P(0) = \mu$ and $P(1) = \nu$. Then
  \begin{align*}
  \JS_\alpha(\mu, \nu) = \inf_{\xi \in \mathcal P(\mathcal X)} \KL\left( \pi_\alpha \otimes P, \pi_\alpha \times \xi \right) \: .
  \end{align*}
  The infimum is attained at $\xi = \alpha \mu + (1 - \alpha) \nu$.
\end{lemma}

Compare with Lemma~\ref{lem:renyi_eq_inf_kl} on the Rényi divergence.

\begin{proof}%\leanok
\uses{}

\end{proof}
