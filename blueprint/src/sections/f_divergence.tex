\chapter{f-divergences}

\section{Definition and basic properties}

\begin{definition}[f-divergence]
  \label{def:fDiv}
  \lean{ProbabilityTheory.fDivReal}
  \leanok
  %\uses{}
  Let $f : \mathbb{R} \to \mathbb{R}$ and let $\mu, \nu$ be two measures on a measurable space $\mathcal X$. The f-divergence between $\mu$ and $\nu$ is
  \begin{align*}
  D_f(\mu, \nu) = \nu\left[x \mapsto f\left(\frac{d \mu}{d \nu}(x)\right)\right]
  \end{align*}
  if $x \mapsto f\left(\frac{d \mu}{d \nu}(x)\right)$ is $\nu$-integrable and $+\infty$ otherwise.
\end{definition}

TODO: whenever necessary, we assume that $f$ is measurable.

\begin{lemma}
  \label{lem:fDiv_add}
  \lean{ProbabilityTheory.fDivReal_add}
  \leanok
  \uses{def:fDiv}
  $D_{f + g}(\mu, \nu) = D_f(\mu, \nu) + D_g(\mu, \nu)$.
\end{lemma}

\begin{proof}
Linearity of the integral.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_self}
  \lean{ProbabilityTheory.fDivReal_self}
  \leanok
  \uses{def:fDiv}
  If $f(1) = 0$ then $D_{f}(\mu, \mu) = 0$.
\end{lemma}

\begin{proof} \leanok
$\frac{d \mu}{d \mu}(x) = 1$ almost everywhere and $f(1) = 0$.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_mul}
  \lean{ProbabilityTheory.fDivReal_mul}
  \leanok
  \uses{def:fDiv}
  For all $a \in \mathbb{R}$, $D_{a f}(\mu, \nu) = a D_{f}(\mu, \nu)$.
\end{lemma}

\begin{proof} \leanok
Linearity of the integral.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_const}
  \lean{ProbabilityTheory.fDivReal_const}
  \leanok
  \uses{def:fDiv}
  For all $a \in \mathbb{R}$, $D_{x \mapsto a}(\mu, \nu) = a \nu(\mathcal X)$.
\end{lemma}

\begin{proof} \leanok
Compute the integral.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_eq_ac}
  \lean{ProbabilityTheory.fDivReal_withDensity_rnDeriv}
  \leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two measures on $\mathcal X$ with $\nu$ $\sigma$-finite. Let $\mu' = \left(\frac{\partial \mu}{\partial \nu}\right) \cdot \nu$.
  Then $D_f(\mu, \nu) = D_f(\mu', \nu)$.
\end{lemma}

\begin{proof} \leanok
For $\nu$-almost all $x$, $\frac{\partial \mu'}{\partial \nu}(x) = \frac{\partial \mu}{\partial \nu}(x)$, hence
\begin{align*}
D_f(\mu', \nu)
= \int_x f\left(\frac{\partial \mu'}{\partial \nu}(x)\right)\partial \nu
= \int_x f\left(\frac{\partial \mu}{\partial \nu}(x)\right)\partial \nu
= D_f(\mu, \nu)
\: .
\end{align*}
\end{proof}

\begin{lemma}
  \label{lem:fDiv_id}
  \lean{ProbabilityTheory.fDivReal_id}
  \leanok
  \uses{def:fDiv}
  For $\mu \ll \nu$, $D_{x \mapsto x}(\mu, \nu) = \mu(\mathcal X)$.
\end{lemma}

\begin{proof} \leanok
Compute the integral. If we don't have $\mu \ll \nu$, we only get $D_{x \mapsto x}(\mu, \nu) \le \mu(\mathcal X)$.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_add_linear}
  \lean{ProbabilityTheory.fDivReal_add_linear}
  \leanok
  \uses{def:fDiv}
  For finite measures $\mu$ and $\nu$ with $\mu \ll \nu$ and $\mu(\mathcal X) = \nu(\mathcal X)$, for all $a \in \mathbb{R}$, $D_{f + a(x - 1)}(\mu, \nu) = D_{f}(\mu, \nu)$.
\end{lemma}

This means that we can always choose $f \ge 0$ and $f'(1) = 0$ if we want (and $f$ is differentiable at $1$).

\begin{proof}
\uses{lem:fDiv_add, lem:fDiv_mul, lem:fDiv_const, lem:fDiv_id}
Linearity (Lemmas~\ref{lem:fDiv_add} and~\ref{lem:fDiv_mul}), then Lemma~\ref{lem:fDiv_const} and~\ref{lem:fDiv_id}.
\end{proof}

\section{Conditional f-divergence}

\begin{lemma}
  \label{lem:measurable_fDiv}
  %\lean{}
  %\leanok
  \uses{def:fDiv}
  Let $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ be two Markov kernels from $\mathcal X$ to $\mathcal Y$. Then $x \mapsto D_f(\kappa(x), \eta(x))$ is measurable.
\end{lemma}

\begin{proof}
\end{proof}

\begin{definition}[Conditional f-divergence]
  \label{def:condFDiv}
  \lean{ProbabilityTheory.condFDivReal}
  \leanok
  \uses{def:fDiv}
  Let $f : \mathbb{R} \to \mathbb{R}$, $\mu$ a measure on $\mathcal X$ and $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ two Markov kernels from $\mathcal X$ to $\mathcal Y$. The conditional f-divergence between $\kappa$ and $\eta$ with respect to $\mu$ is
  \begin{align*}
  D_f(\kappa, \eta \mid \mu) = \mu\left[x \mapsto D_f(\kappa(x), \eta(x))\right]
  \end{align*}
  if $x \mapsto D_f(\kappa(x), \eta(x))$ is $\mu$-integrable and $+\infty$ otherwise.
\end{definition}

\begin{lemma}
  \label{lem:integrable_fDiv_compProd_iff}
  \lean{ProbabilityTheory.integrable_f_rnDeriv_compProd_iff}
  \leanok
  \uses{def:fDiv}
  Let $\mu$ be a finite measure on $\mathcal X$ and $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ be two finite kernels from $\mathcal X$ to $\mathcal Y$.
  Then $p \mapsto f \left(\frac{d(\mu \otimes \kappa)}{d(\mu \otimes \eta)}(p)\right)$ is $(\mu \otimes \eta)$-integrable iff
  \begin{itemize}
    \item $x \mapsto D_f(\kappa(x), \eta(x))$ is $\mu$-integrable and
    \item for $\mu$-almost all $x$, $y \mapsto f \left( \frac{d\kappa(x)}{d\eta(x)}(y) \right)$ is $\eta(x)$-integrable. 
  \end{itemize}
\end{lemma}

\begin{proof}
Since $x \mapsto f \left(\frac{d(\mu \otimes \kappa)}{d(\mu \otimes \eta)} x \right)$ is measurable, the integrability condition w.r.t. $\mu \otimes \eta$ is equivalent to
\begin{itemize}
    \item $x \mapsto \int_y \left\Vert f \left( \frac{d\kappa(x)}{d\eta(x)}(y) \right) \right\Vert \partial \eta(x)$ is $\mu$-integrable and
    \item for $\mu$-almost all $x$, $y \mapsto f \left( \frac{d\kappa(x)}{d\eta(x)}(y) \right)$ is $\eta(x)$-integrable. 
  \end{itemize}
It suffices to use convexity to show that integrability of $x \mapsto \int_y f \left( \frac{d\kappa(x)}{d\eta(x)}(y) \right) \partial \eta(x)$ implies integrability of $x \mapsto \int_y \left\Vert f \left( \frac{d\kappa(x)}{d\eta(x)}(y) \right) \right\Vert \partial \eta(x)$.

TODO
\end{proof}

\begin{lemma}
  \label{lem:fDiv_compProd_left}
  \lean{ProbabilityTheory.fDivReal_compProd_left}
  \leanok
  \uses{def:fDiv, def:condFDiv}
  Let $\mu$ be a finite measure on $\mathcal X$ and let $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ be two finite kernels.
  Then $D_f(\mu \otimes \kappa, \mu \otimes \eta) = D_f(\kappa, \eta \mid \mu)$.
\end{lemma}

\begin{proof} \leanok
\uses{cor:rnDeriv_compProd_right, cor:rnDeriv_value, lem:integrable_fDiv_compProd_iff}
By Lemma~\ref{lem:integrable_fDiv_compProd_iff}, the conditions on which the two divergences are finite are the same. We then assume integrability properties such that both are finite.

By Lemma~\ref{cor:rnDeriv_compProd_right} and Corollary~\ref{cor:rnDeriv_value},
\begin{align*}
D_f(\mu \otimes \kappa, \mu \otimes \eta)
&= \int_{p} f\left(\frac{d (\mu \otimes \kappa)}{d (\mu \otimes \eta)}(p)\right) \partial(\mu \otimes \eta)
\\
&= \int_{p} f\left(\frac{d \kappa}{d \eta}(p)\right) \partial(\mu \otimes \eta)
\\
&= \int_x \int_y f\left(\frac{d \kappa}{d \eta}(x, y)\right) \partial \eta(x) \partial \mu
\\
&= \int_x \int_y f\left(\frac{d \kappa(x)}{d \eta(x)}(y)\right) \partial \eta(x) \partial \mu
\\
&= \mu\left[D_f(\kappa(x), \eta(x))\right]
= D_f(\kappa, \eta \mid \mu)
\: .
\end{align*}
\end{proof}

\section{Data-processing inequality}

\begin{lemma}
  \label{lem:fDiv_compProd_eq_ac}
  \lean{ProbabilityTheory.fDivReal_compProd_withDensity_rnDeriv}
  \leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ be two finite kernels. Let $\mu' = \left(\frac{\partial \mu}{\partial \nu}\right) \cdot \nu$ and $\kappa' = \left(\frac{\partial \kappa}{\partial \eta}\right) \cdot \eta$.
  Then $D_f(\mu \otimes \kappa, \nu \otimes \eta) = D_f(\mu' \otimes \kappa', \nu \otimes \eta)$.
\end{lemma}

\begin{proof} \leanok
\uses{lem:rnDeriv_eq_ac}
By Lemma~\ref{lem:rnDeriv_eq_ac}, for $(\nu \otimes \eta)$-almost all $z$, $\frac{\partial(\mu' \otimes \kappa')}{\partial(\nu \otimes \eta)}(z) = \frac{\partial(\mu \otimes \kappa)}{\partial(\nu \otimes \eta)}(z)$, hence
\begin{align*}
D_f(\mu' \otimes \kappa', \nu \otimes \eta)
&= \int_z f\left(\frac{\partial(\mu' \otimes \kappa')}{\partial(\nu \otimes \eta)}\right) \partial(\nu \otimes \eta)
\\
&= \int_z f\left(\frac{\partial(\mu \otimes \kappa)}{\partial(\nu \otimes \eta)}\right) \partial(\nu \otimes \eta)
\\
&= D_f(\mu \otimes \kappa, \nu \otimes \eta)
\: .
\end{align*}

\end{proof}

\begin{theorem}[Marginals]
  \label{thm:fDiv_fst_le}
  %\lean{}
  %\leanok
  \uses{def:fDiv}
  Let $\mu$ and $\nu$ be two measures on $\mathcal X \times \mathcal Y$ where $\mathcal Y$ is standard Borel, and let $\mu_X, \nu_X$ be their marginals on $\mathcal X$.
  Then $D_f(\mu_X, \nu_X) \le D_f(\mu, \nu)$.
  Similarly, for $\mathcal X$ standard Borel and $\mu_Y, \nu_Y$ the marginals on $\mathcal Y$, $D_f(\mu_Y, \nu_Y) \le D_f(\mu, \nu)$.
\end{theorem}

\begin{proof}
\uses{lem:rnDeriv_compProd, cor:rnDeriv_value, lem:fDiv_eq_ac, lem:fDiv_compProd_eq_ac}
We first introduce conditional kernels and write $D(\mu, \nu) = D(\mu_X \otimes \mu_{Y|X}, \nu_X \otimes \nu_{Y|X})$. By Lemmas~\ref{lem:fDiv_eq_ac} and \ref{lem:fDiv_compProd_eq_ac}, it suffices to prove the result for $\mu_X \ll \nu_X$ and $\mu_{Y|X}(x) \ll \nu_{Y|X}(x)$ for all $x$.

Using Lemma~\ref{lem:rnDeriv_compProd} and \ref{cor:rnDeriv_value},
\begin{align*}
D(\mu, \nu)
&= D(\mu_X \otimes \mu_{Y|X}, \nu_X \otimes \nu_{Y|X})
\\
&= \int_x \int_y f \left( \frac{\partial \mu_X}{\partial\nu_X}(x) \frac{\partial \mu_{Y|X}(x)}{\partial\nu_{Y|X}(x)}(y) \right) \partial \nu_{Y|X}(x) \partial \nu_X
\: .
\end{align*}
Since $f$ is convex, by Jensen's inequality,
\begin{align*}
\int_y f \left( \frac{\partial \mu_X}{\partial\nu_X}(x) \frac{\partial \mu_{Y|X}(x)}{\partial\nu_{Y|X}(x)}(y) \right) \partial \nu_{Y|X}(x)
&\ge f \left( \int_y \frac{\partial \mu_X}{\partial\nu_X}(x) \frac{\partial \mu_{Y|X}(x)}{\partial\nu_{Y|X}(x)}(y) \partial \nu_{Y|X}(x) \right)
\\
&= f \left( \frac{\partial \mu_X}{\partial\nu_X}(x) \int_y \frac{\partial \mu_{Y|X}(x)}{\partial\nu_{Y|X}(x)}(y) \partial \nu_{Y|X}(x) \right)
\: .
\end{align*}

Since $\mu_{Y|X}(x) \ll \nu_{Y|X}(x)$ for all $x$, $\int_y \frac{\partial \mu_{Y|X}(x)}{\partial\nu_{Y|X}(x)}(y) \partial \nu_{Y|X}(x) = \int_y 1 \partial \mu_{Y|X}(x) = 1$. We have obtained
\begin{align*}
D_f(\mu, \nu)
\ge \int_x f \left( \frac{\partial \mu_X}{\partial\nu_X}(x)\right) \partial \nu_X
= D_f(\mu_X, \nu_X)
\: .
\end{align*}

\end{proof}

\begin{lemma}[Composition-product with a kernel]
  \label{thm:fDiv_compProd_right}
  \lean{ProbabilityTheory.fDivReal_compProd_right}
  \leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $\kappa : \mathcal X \rightsquigarrow \mathcal Y$ be a Markov kernel.
  Then $D_f(\mu \otimes \kappa, \nu \otimes \kappa) = D_f(\mu, \nu)$.
\end{lemma}

\begin{proof}
\uses{cor:rnDeriv_compProd_left}
By Corollary~\ref{cor:rnDeriv_compProd_left},
\begin{align*}
D_f(\mu \otimes \kappa, \nu \otimes \kappa)
&= \int_{p} f\left(\frac{d (\mu \otimes \kappa)}{d (\nu \otimes \kappa)}(p)\right) \partial(\nu \otimes \kappa)
\\
&= \int_{p} f\left(\frac{d \mu}{d \nu}(p_X)\right) \partial(\nu \otimes \kappa)
\\
&= \int_x \int_y f\left(\frac{d \mu}{d \nu}(x)\right) \partial \kappa(x) \partial \nu
\\
&= \int_x f\left(\frac{d \mu}{d \nu}(x)\right) \partial \nu
\\
&= D_f(\mu, \nu)
\: .
\end{align*}
\end{proof}

\begin{corollary}
  \label{cor:fDiv_prod_right}
  %\lean{}
  %\leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $\xi$ be a measure on $\mathcal Y$.
  Then $D_f(\mu \times \xi, \nu \times \xi) = D_f(\mu, \nu)$.
\end{corollary}

\begin{proof}
\uses{thm:fDiv_compProd_right}
Apply Lemma~\ref{thm:fDiv_compProd_right} with $\kappa$ the constant kernel with value $\xi$.
\end{proof}

\begin{theorem}[Conditioning increases f-divergence]
  \label{thm:fDiv_comp_le_condFDiv}
  %\lean{}
  %\leanok
  \uses{def:fDiv, def:condFDiv}
  Let $\mu$ be a measure on $\mathcal X$ and let $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ be two Markov kernels.
  Then $D_f(\kappa \circ \mu, \eta \circ \mu) \le D_f(\mu \otimes \kappa, \mu \otimes \eta) = D_f(\kappa, \eta \mid \mu)$
\end{theorem}

\begin{proof}
\uses{thm:fDiv_fst_le, lem:fDiv_compProd_left}
By definition, $\kappa \circ \mu$ is the marginal of $\mu \otimes \kappa$ (a measure on $\mathcal X \times \mathcal Y$) on $\mathcal Y$. Hence by Theorem~\ref{thm:fDiv_fst_le}, $D_f(\kappa \circ \mu, \eta \circ \mu) \le D_f(\mu \otimes \kappa, \mu \otimes \eta)$. This is equal to $D_f(\kappa, \eta \mid \mu)$ by Lemma~\ref{lem:fDiv_compProd_left}.
\end{proof}

\begin{theorem}[Data-processing]
  \label{thm:fDiv_data_proc}
  %\lean{}
  %\leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $\kappa : \mathcal X \rightsquigarrow \mathcal Y$ be a Markov kernel.
  Then $D_f(\kappa \circ \mu, \kappa \circ \nu) \le D_f(\mu, \nu)$.
\end{theorem}

\begin{proof}
\uses{thm:fDiv_fst_le, thm:fDiv_compProd_right}
By definition, $\kappa \circ \mu$ is the marginal of $\mu \otimes \kappa$ (a measure on $\mathcal X \times \mathcal Y$) on $\mathcal Y$. Hence by Theorem~\ref{thm:fDiv_fst_le}, $D_f(\kappa \circ \mu, \kappa \circ \nu) \le D_f(\mu \otimes \kappa, \nu \otimes \kappa)$. Then the latter is equal to $D_f(\mu, \nu)$ by Lemma~\ref{thm:fDiv_compProd_right}.
\end{proof}

\begin{corollary}
  \label{cor:data_proc_event}
  %\lean{}
  %\leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $E$ be an event. Let $\mu_E$ and $\nu_E$ be the two Bernoulli distributions with respective means $\mu(E)$ and $\nu(E)$. Then $D_f(\mu, \nu) \ge D_f(\mu_E, \nu_E)$.
\end{corollary}

\begin{proof}
\uses{thm:fDiv_data_proc}
Use the deterministic kernel $\kappa : \mathcal X \rightsquigarrow \{0, 1\}$ with $\kappa(x) = \delta_1 \mathbb{I}\{x \in E\} + \delta_0 \mathbb{I}\{x \notin E\}$ in Theorem~\ref{thm:fDiv_data_proc}.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_nonneg}
  \lean{ProbabilityTheory.fDivReal_nonneg}
  \leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two probability measures on $\mathcal X$. If $f(1) = 0$, $D_f(\mu, \nu) \ge 0$.
\end{lemma}

\begin{proof} \leanok
\uses{thm:fDiv_data_proc, lem:fDiv_self}
TODO: the lean proof is different.

Take $\kappa : \mathcal X \rightsquigarrow (*)$ the constant kernel to a type with only 1 element, with $\kappa(x) = \delta_*$ (the dirac measure at the element $*$).
Then by Theorem~\ref{thm:fDiv_data_proc} and Lemma~\ref{lem:fDiv_self}, $D_f(\mu, \nu) \ge D_f(\kappa \circ \mu, \kappa \circ \nu) = D_f(\delta_*, \delta_*) = 0$.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_compProd_prod_eq}
  %\lean{}
  %\leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $\kappa : \mathcal X \rightsquigarrow (\mathcal X \times \mathcal Y)$ be a Markov kernel such that for all $x$, $(\kappa(x))_X = \delta_x$. Then $D_f(\kappa \circ \mu, \kappa \circ \nu) = D_f(\mu, \nu)$.
\end{lemma}

\begin{proof}
\uses{thm:fDiv_data_proc, thm:fDiv_fst_le}
$D_f(\kappa \circ \mu, \kappa \circ \nu) \le D_f(\mu, \nu)$ by Theorem~\ref{thm:fDiv_data_proc}.
For the other inequality, remark that $\mu = (\kappa \circ \mu)_X$ (and similarly for $\nu$). Hence by Theorem~\ref{thm:fDiv_fst_le} $D_f(\mu, \nu) \le D_f(\kappa \circ \mu, \kappa \circ \nu)$.
\end{proof}

\section{Convexity}

\begin{theorem}[Joint convexity]
  \label{thm:fDiv_convex}
  %\lean{}
  %\leanok
  \uses{def:fDiv}
  The function $(\mu, \nu) \mapsto D_f(\mu, \nu)$ is convex.
\end{theorem}

\begin{proof}
\uses{thm:fDiv_comp_le_condFDiv}
Let $\mu_0, \mu_1, \nu_0, \nu_1$ be four measures. Let $\lambda \in [0,1]$. Let $\xi$ be the probability measure on $\{0,1\}$ with $\xi(\{1\}) = \lambda$.
Let $\kappa$ be the kernel $\{0,1\} \rightsquigarrow \mathcal X$ defined by $\kappa(0) = \mu_0$ and $\kappa(1) = \mu_1$.
Let $\eta$ be the kernel $\{0,1\} \rightsquigarrow \mathcal X$ defined by $\eta(0) = \nu_0$ and $\eta(1) = \nu_1$.
\begin{align*}
D_f(\xi \otimes \kappa, \xi \otimes \eta)
&= D_f(\kappa, \eta \mid \xi)
= (1 - \lambda) D_f(\mu_0, \nu_0) + \lambda D_f(\mu_1, \nu_1)
\: , \\
D_f(\kappa \circ \xi, \eta \circ \xi)
&= D_f((1 - \lambda)\mu_0 + \lambda \mu_1, (1 - \lambda)\nu_0 + \lambda \nu_1)
\: .
\end{align*}
By Theorem~\ref{thm:fDiv_comp_le_condFDiv}, $D_f(\kappa \circ \xi, \eta \circ \xi) \le D_f(\xi \otimes \kappa, \xi \otimes \eta)$.
\end{proof}

\section{Variational representations}

TODO