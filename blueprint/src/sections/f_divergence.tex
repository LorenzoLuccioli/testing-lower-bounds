\chapter{f-divergences}

\section{Definition and basic properties}

Everywhere in this document, the functions used in divergences are assumed measurable, continuous and convex on $[0, +\infty)$.
For such a function $f : \mathbb{R} \to \mathbb{R}$, we write $f'(\infty) = \lim_{x \to +\infty} f(x)/x$ (which can be infinite).

For $\mu, \nu$ two measures, we denote by $\mu_{\perp \nu}$ the singular part of $\mu$ with respect to $\nu$.

\begin{definition}[f-divergence]
  \label{def:fDiv}
  \lean{ProbabilityTheory.fDiv}
  \leanok
  \uses{def:derivAtTop}
  Let $f : \mathbb{R} \to \mathbb{R}$ and let $\mu, \nu$ be two measures on a measurable space $\mathcal X$. The f-divergence between $\mu$ and $\nu$ is
  \begin{align*}
  D_f(\mu, \nu) = \nu\left[x \mapsto f\left(\frac{d \mu}{d \nu}(x)\right)\right] + f'(\infty) \mu_{\perp \nu}(\mathcal X)
  \end{align*}
  if $x \mapsto f\left(\frac{d \mu}{d \nu}(x)\right)$ is $\nu$-integrable and $+\infty$ otherwise.
\end{definition}

\begin{lemma}
  \label{lem:fDiv_ne_top_iff}
  \lean{ProbabilityTheory.fDiv_ne_top_iff}
  \leanok
  \uses{def:fDiv}
  For $\mu$ and $\nu$ two finite measures, $D_f(\mu, \nu)$ is finite if and only if $x \mapsto f\left(\frac{d \mu}{d \nu}(x)\right)$ is $\nu$-integrable and either $f'(\infty) < \infty$ or $\mu \ll \nu$.
\end{lemma}

\begin{proof}\leanok
\end{proof}

\begin{lemma}
  \label{lem:fDiv_const}
  \lean{ProbabilityTheory.fDiv_const}
  \leanok
  \uses{def:fDiv}
  For $\nu$ a finite measure, for all $a \in \mathbb{R}$, $D_{x \mapsto a}(\mu, \nu) = a \nu(\mathcal X)$.
\end{lemma}

\begin{proof} \leanok
Compute the integral.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_self}
  \lean{ProbabilityTheory.fDiv_self}
  \leanok
  \uses{def:fDiv}
  If $f(1) = 0$ then $D_{f}(\mu, \mu) = 0$.
\end{lemma}

\begin{proof} \leanok
$\frac{d \mu}{d \mu}(x) = 1$ almost everywhere and $f(1) = 0$.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_id}
  \lean{ProbabilityTheory.fDiv_id}
  \leanok
  \uses{def:fDiv}
  $D_{x \mapsto x}(\mu, \nu) = \mu(\mathcal X)$.
\end{lemma}

\begin{proof} \leanok
Compute the integral: its value is $(\frac{d\mu}{d\nu}\cdot \nu)(\mathcal X)$. Then
$D_{x\mapsto x}(\mu, \nu) = (\frac{d\mu}{d\nu}\cdot \nu)(\mathcal X) + \mu_{\perp \nu}(\mathcal X) = \mu (\mathcal X)$.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_mul}
  \lean{ProbabilityTheory.fDiv_mul}
  \leanok
  \uses{def:fDiv}
  For all $a \ge 0$, $D_{a f}(\mu, \nu) = a D_{f}(\mu, \nu)$.
\end{lemma}

\begin{proof}\leanok
Linearity of the integral.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_add}
  \lean{ProbabilityTheory.fDiv_add}
  \leanok
  \uses{def:fDiv}
  $D_{f + g}(\mu, \nu) = D_f(\mu, \nu) + D_g(\mu, \nu)$.
\end{lemma}

\begin{proof}\leanok
Linearity of the integral.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_add_linear}
  \lean{ProbabilityTheory.fDiv_add_linear}
  \leanok
  \uses{def:fDiv}
  For finite measures $\mu$ and $\nu$ with $\mu(\mathcal X) = \nu(\mathcal X)$, for all $a \ge 0$, $D_{f + a(x - 1)}(\mu, \nu) = D_{f}(\mu, \nu)$.
\end{lemma}

\begin{proof}\leanok
\uses{lem:fDiv_add, lem:fDiv_mul, lem:fDiv_const, lem:fDiv_id}
Linearity (Lemmas~\ref{lem:fDiv_add} and~\ref{lem:fDiv_mul}), then Lemma~\ref{lem:fDiv_const} and~\ref{lem:fDiv_id}.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_map_measurableEmbedding}
  \lean{ProbabilityTheory.fDiv_map_measurableEmbedding}
  \leanok
  \uses{def:fDiv}
  Let $\mu$ and $\nu$ be two measures on $\mathcal X$ and let $g : \mathcal X \to \mathcal Y$ be a measurable embedding. Then $D_f(g_* \mu, g_* \nu) = D_f(\mu, \nu)$.
\end{lemma}

\begin{proof}\leanok
\end{proof}

\begin{lemma}
  \label{lem:fDiv_absolutelyContinuous_add_mutuallySingular}
  \lean{ProbabilityTheory.fDiv_absolutelyContinuous_add_mutuallySingular}
  \leanok
  \uses{def:fDiv}
  Let $\mu_1, \mu_2$ and $\nu$ be finite measures on $\mathcal X$, with $\mu_1 \ll \nu$ and $\mu_2 \perp \nu$.
  Then $D_f(\mu_1 + \mu_2, \nu) = D_f(\mu_1, \nu) + \mu_2(\mathcal X) f'(\infty)$.
\end{lemma}

\begin{proof}\leanok
$\frac{d(\mu_1 + \mu_2)}{d \nu} = \frac{d \mu_1}{d \nu}$ a.e. and $(\mu_1 + \mu_2)_{\perp \nu} = \mu_2$.
\end{proof}

\begin{lemma}[Superseded by Lemma~\ref{lem:fDiv_add_measure_le}]
  \label{lem:fDiv_add_measure_le_of_ac}
  \lean{ProbabilityTheory.fDiv_add_measure_le_of_ac}
  \leanok
  \uses{def:fDiv}
  Let $\mu_1, \mu_2, \nu$ be three finite measures on $\mathcal X$ with $\mu_1 \ll \nu$ and $\mu_2 \ll \nu$. Then
  $D_f(\mu_1 + \mu_2, \nu) \le D_f(\mu_1, \nu) + \mu_2(\mathcal X) f'(\infty)$.
\end{lemma}

\begin{proof}\leanok
\begin{align*}
D_f(\mu_1 + \mu_2, \nu)
&= \int_x f \left( \frac{d \mu_1}{d\nu}(x) + \frac{d\mu_2}{d\nu}(x) \right) \partial \nu
\\
&\le \int_x f \left( \frac{d \mu_1}{d\nu}(x) \right) + \frac{d\mu_2}{d\nu}(x) f'(\infty) \partial \nu
\\
&= D_f(\mu_1, \nu) + \mu_2(\mathcal X) f'(\infty)
\: .
\end{align*}
\end{proof}

\begin{lemma}
  \label{lem:fDiv_add_measure_le}
  \lean{ProbabilityTheory.fDiv_add_measure_le}
  \leanok
  \uses{def:fDiv}
  Let $\mu_1, \mu_2, \nu$ be three finite measures on $\mathcal X$. Then
  $D_f(\mu_1 + \mu_2, \nu) \le D_f(\mu_1, \nu) + \mu_2(\mathcal X) f'(\infty)$.
\end{lemma}

\begin{proof}\leanok
\uses{lem:fDiv_absolutelyContinuous_add_mutuallySingular, lem:fDiv_add_measure_le_of_ac}
From Lemma~\ref{lem:fDiv_absolutelyContinuous_add_mutuallySingular}, then Lemma~\ref{lem:fDiv_add_measure_le_of_ac},
\begin{align*}
D_f(\mu_1 + \mu_2, \nu)
&= D_f(\frac{d\mu_1}{d \nu}\cdot \nu + \frac{d\mu_2}{d \nu}\cdot \nu, \nu) + (\mu_1)_{\perp\nu}(\mathcal X) f'(\infty) + (\mu_2)_{\perp\nu}(\mathcal X) f'(\infty)
\\
&\le D_f(\frac{d\mu_1}{d \nu}\cdot \nu, \nu) + (\frac{d\mu_2}{d \nu}\cdot \nu)(\mathcal X) f'(\infty) + (\mu_1)_{\perp\nu}(\mathcal X) f'(\infty) + (\mu_2)_{\perp\nu}(\mathcal X) f'(\infty)
\\
&= D_f(\mu_1, \nu) + \mu_2(\mathcal X) f'(\infty)
\: .
\end{align*}
\end{proof}

\begin{lemma}
  \label{lem:fDiv_eq_add_withDensity_derivAtTop}
  \lean{ProbabilityTheory.fDiv_eq_add_withDensity_derivAtTop}
  \leanok
  \uses{def:fDiv}
  Let $\mu$ and $\nu$ be two finite measures on $\mathcal X$.
  Then $D_f(\mu, \nu) = D_f(\frac{d\mu}{d\nu}\cdot \nu, \nu) + f'(\infty) \mu_{\perp \nu}(\mathcal X)$.
\end{lemma}

\begin{proof}\leanok
\uses{lem:fDiv_absolutelyContinuous_add_mutuallySingular}
Apply Lemma~\ref{lem:fDiv_absolutelyContinuous_add_mutuallySingular} to $\frac{d\mu}{d\nu}\cdot \nu$ and $\mu_{\perp \nu}$.
\end{proof}

\begin{lemma}[Superseded by Lemma~\ref{lem:le_fDiv}]
  \label{lem:le_fDiv_of_ac}
  \lean{ProbabilityTheory.le_fDiv_of_ac}
  \leanok
  \uses{def:fDiv}
  Let $\mu$ be a finite measure and $\nu$ be a probability measure on the same space $\mathcal X$, such that $\mu \ll \nu$. Then $f(\mu(\mathcal X)) \le D_f(\mu, \nu)$.
\end{lemma}

\begin{proof}\leanok
Since $\mu \ll \nu$ the $f$-divergence is only the integral part. Then by Jensen's inequality,
\begin{align*}
D_f(\mu, \nu)
&= \nu\left[ f\left( \frac{d\mu}{d\nu} \right) \right]
\ge f\left( \nu\left[\frac{d\mu}{d\nu} \right] \right)
= f(\mu(\mathcal X))
\: .
\end{align*}

\end{proof}

\begin{lemma}
  \label{lem:le_fDiv}
  \lean{ProbabilityTheory.le_fDiv}
  \leanok
  \uses{def:fDiv}
  Let $\mu$ be a finite measure and $\nu$ be a probability measure on the same space $\mathcal X$. Then $f(\mu(\mathcal X)) \le D_f(\mu, \nu)$.
\end{lemma}

\begin{proof}\leanok
\uses{lem:fDiv_eq_add_withDensity_derivAtTop, lem:le_fDiv_of_ac}
By convexity, then Lemma~\ref{lem:le_fDiv_of_ac} and finally Lemma~\ref{lem:fDiv_eq_add_withDensity_derivAtTop},
\begin{align*}
f(\mu(\mathcal X))
&\le f(\frac{d\mu}{d\nu}\cdot \nu (\mathcal X)) + f'(\infty)\mu_{\perp}(\mathcal X)
\\
&\le D_f(\frac{d\mu}{d\nu}\cdot \nu , \nu) + f'(\infty)\mu_{\perp}(\mathcal X)
\\
&= D_f(\mu, \nu)
\: .
\end{align*}
\end{proof}

\begin{lemma}
  \label{lem:fDiv_nonneg}
  \lean{ProbabilityTheory.fDiv_nonneg}
  \leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two probability measures. If $f(1) = 0$ then $D_f(\mu, \nu) \ge 0$.
\end{lemma}

\begin{proof}\leanok
\uses{lem:le_fDiv}
Apply Lemma~\ref{lem:le_fDiv} and use $f(\mu(\mathcal X)) = f(1) = 0$.
\end{proof}

\section{Data-processing inequality: sigma-algebras}

For $\mathcal A$ a sub-$\sigma$-algebra and $\mu$ a measure, we write $\mathcal \mu_{| \mathcal A}$ for the measure restricted to the $\sigma$-algebra.

\begin{lemma}
  \label{lem:rnDeriv_trim_of_ac}
  \lean{MeasureTheory.Measure.toReal_rnDeriv_trim_of_ac}
  \leanok
  %\uses{}
  Let $\mu, \nu$ be two finite measures on $\mathcal X$ with $\mu \ll \nu$ and let $\mathcal A$ be a sub-$\sigma$-algebra of $\mathcal X$.
  Then $\frac{d \mu_{| \mathcal A}}{d \nu_{| \mathcal A}}$ is $\nu_{| \mathcal A}$-almost everywhere (hence also $\nu$-a.e.) equal to $\nu\left[ \frac{d \mu}{d \nu} \mid \mathcal A\right]$.
\end{lemma}

\begin{proof}\leanok
\end{proof}

\begin{lemma}
  \label{lem:fDiv_trim_le_of_ac}
  \lean{ProbabilityTheory.fDiv_trim_le_of_ac}
  \leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two finite measures on $\mathcal X$ with $\mu \ll \nu$ and let $\mathcal A$ be a sub-$\sigma$-algebra of $\mathcal X$. Then
  $D_f(\mu_{| \mathcal A}, \nu_{| \mathcal A}) \le D_f(\mu, \nu)$.
\end{lemma}

\begin{proof}\leanok
\uses{thm:condexp_jensen, lem:rnDeriv_trim_of_ac}
Since $\mu \ll \nu$, $\mu_{| \mathcal A} \ll \nu_{| \mathcal A}$ and
\begin{align*}
D_f(\mu_{| \mathcal A}, \nu_{| \mathcal A})
&= \int_x f \left( \frac{d \mu_{| \mathcal A}}{d \nu_{| \mathcal A}}(x) \right) \partial\nu_{| \mathcal A} \: .
\end{align*}
Since $f \left( \frac{d \mu_{| \mathcal A}}{d \nu_{| \mathcal A}} \right)$ is $\mathcal A$-measurable, this integral is equal to the integral w.r.t. $\nu$.
By Lemma~\ref{lem:rnDeriv_trim_of_ac}, this is equal to $\int_x f \left( \nu\left[ \frac{d \mu}{d \nu} \mid \mathcal A\right] (x) \right) \partial\nu$.

By Theorem~\ref{thm:condexp_jensen}, $f \left( \nu\left[ \frac{d \mu}{d \nu} \mid \mathcal A\right] (x) \right) \le \nu\left[ f \circ \frac{d \mu}{d \nu} \mid \mathcal A\right] (x)$ almost everywhere.
Finally
\begin{align*}
D_f(\mu_{| \mathcal A}, \nu_{| \mathcal A})
&= \int_x f \left( \nu\left[ \frac{d \mu}{d \nu} \mid \mathcal A\right] (x) \right) \partial\nu
\\
&\le \int_x \nu\left[ f \circ \frac{d \mu}{d \nu} \mid \mathcal A\right] (x) \partial\nu
\\
&= \int_x f \left( \frac{d \mu}{d \nu} (x) \right) \partial\nu
\\
&= D_f(\mu, \nu)
\: .
\end{align*}

\end{proof}

\begin{theorem}
  \label{thm:fDiv_trim_le}
  \lean{ProbabilityTheory.fDiv_trim_le}
  \leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two finite measures on $\mathcal X$ and let $\mathcal A$ be a sub-$\sigma$-algebra of $\mathcal X$. Then
  $D_f(\mu_{| \mathcal A}, \nu_{| \mathcal A}) \le D_f(\mu, \nu)$.
\end{theorem}

\begin{proof}\leanok
\uses{lem:fDiv_trim_le_of_ac, lem:fDiv_add_measure_le}
We decompose $\mu_{| \mathcal A}$ into two parts: $\mu_{| \mathcal A} = (\frac{d\mu}{d\nu}\cdot \nu)_{| \mathcal A} + (\mu_{\perp \nu})_{| \mathcal A}$~. 
We have $(\frac{d\mu}{d\nu}\cdot \nu)_{| \mathcal A} \ll \nu_{| \mathcal A}$.
By Lemma~\ref{lem:fDiv_add_measure_le},
\begin{align*}
D_f(\mu_{| \mathcal A}, \nu_{| \mathcal A})
\le D_f\left((\frac{d\mu}{d\nu}\cdot \nu)_{| \mathcal A}, \nu_{| \mathcal A}\right)
  + (\mu_{\perp \nu})_{| \mathcal A}(\mathcal X) f'(\infty)
\: .
\end{align*}
Then we apply Lemma~\ref{lem:fDiv_trim_le_of_ac} to the first term to get
\begin{align*}
D_f(\mu_{| \mathcal A}, \nu_{| \mathcal A})
&\le D_f\left(\frac{d\mu}{d\nu}\cdot \nu, \nu\right)
  + (\mu_{\perp \nu})_{| \mathcal A}(\mathcal X) f'(\infty)
\\
&= D_f\left(\frac{d\mu}{d\nu}\cdot \nu, \nu\right)
  + \mu_{\perp \nu}(\mathcal X) f'(\infty)
\\
&= D_f(\mu, \nu)
\: .
\end{align*}
\end{proof}

\begin{theorem}
  \label{thm:iSup_fDiv_trim}
  %\lean{}
  %\leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two finite measures on $\mathcal X$. Then
  $\sup_{\mathcal A \text{ finite}} D_f(\mu_{| \mathcal A}, \nu_{| \mathcal A}) = D_f(\mu, \nu)$.
\end{theorem}

\begin{proof}
\uses{thm:fDiv_trim_le}
\end{proof}

\section{Conditional f-divergence}

\begin{definition}[Conditional f-divergence]
  \label{def:condFDiv}
  \lean{ProbabilityTheory.condFDiv}
  \leanok
  \uses{def:fDiv}
  Let $f : \mathbb{R} \to \mathbb{R}$, $\mu$ a measure on $\mathcal X$ and $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ two Markov kernels from $\mathcal X$ to $\mathcal Y$. The conditional f-divergence between $\kappa$ and $\eta$ with respect to $\mu$ is
  \begin{align*}
  D_f(\kappa, \eta \mid \mu) = \mu\left[x \mapsto D_f(\kappa(x), \eta(x))\right]
  \end{align*}
  if $x \mapsto D_f(\kappa(x), \eta(x))$ is $\mu$-integrable and $+\infty$ otherwise.
\end{definition}

\begin{lemma}
  \label{lem:condFDiv_nonneg}
  \lean{ProbabilityTheory.condFDiv_nonneg}
  \leanok
  \uses{def:condFDiv}
  Let $\mu$ be a measure on $\mathcal X$ and $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ two Markov kernels. If $f(1) = 0$ then $D_f(\kappa, \eta \mid \mu) \ge 0$.
\end{lemma}

\begin{proof}\leanok
\uses{lem:fDiv_nonneg}
Apply Lemma~\ref{lem:fDiv_nonneg}.
\end{proof}

% TODO : this statement is not the same as the lean code, in particular here there is only one measure mentioned, while in the lean we have 2, also the rest of the statement is not the same
\begin{lemma}
  \label{lem:integrable_fDiv_compProd_iff}
  \lean{ProbabilityTheory.integrable_f_rnDeriv_compProd_iff}
  \leanok
  \uses{def:fDiv}
  Let $\mu$ be a finite measure on $\mathcal X$ and $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ be two finite kernels from $\mathcal X$ to $\mathcal Y$.
  Then $p \mapsto f \left(\frac{d(\mu \otimes \kappa)}{d(\mu \otimes \eta)}(p)\right)$ is $(\mu \otimes \eta)$-integrable iff
  \begin{itemize}
    \item $x \mapsto D_f(\kappa(x), \eta(x))$ is $\mu$-integrable and
    \item for $\mu$-almost all $x$, $y \mapsto f \left( \frac{d\kappa(x)}{d\eta(x)}(y) \right)$ is $\eta(x)$-integrable. 
  \end{itemize}
\end{lemma}

\begin{proof}
Since $x \mapsto f \left(\frac{d(\mu \otimes \kappa)}{d(\mu \otimes \eta)} x \right)$ is measurable, the integrability condition w.r.t. $\mu \otimes \eta$ is equivalent to
\begin{itemize}
    \item $x \mapsto \int_y \left\Vert f \left( \frac{d\kappa(x)}{d\eta(x)}(y) \right) \right\Vert \partial \eta(x)$ is $\mu$-integrable and
    \item for $\mu$-almost all $x$, $y \mapsto f \left( \frac{d\kappa(x)}{d\eta(x)}(y) \right)$ is $\eta(x)$-integrable. 
  \end{itemize}
It suffices to use convexity to show that integrability of $x \mapsto \int_y f \left( \frac{d\kappa(x)}{d\eta(x)}(y) \right) \partial \eta(x)$ implies integrability of $x \mapsto \int_y \left\Vert f \left( \frac{d\kappa(x)}{d\eta(x)}(y) \right) \right\Vert \partial \eta(x)$.

TODO
\end{proof}

\begin{lemma}
  \label{lem:condFDiv_ne_top_iff}
  \lean{ProbabilityTheory.condFDiv_ne_top_iff}
  \leanok
  \uses{def:fDiv, def:condFDiv}
  Let $\mu$ be a finite measure on $\mathcal X$ and let $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ be two finite kernels, where $\kappa$ is a Markov kernel.
  Then $D_f(\kappa, \eta \mid \mu) \ne \infty$ if and only if
  \begin{itemize}
    \item for $\mu$-almost all $x$, $y \mapsto f \left( \frac{d\kappa(x)}{d\eta(x)}(y) \right)$ is $\eta(x)$-integrable,
    \item $x \mapsto \int_y f \left( \frac{d\kappa(x)}{d\eta(x)}(y) \right) \partial \eta(x)$ is $\mu$-integrable,
    \item either $f'(\infty) < \infty$ or for $\mu$-almost all $x$, $\kappa(x) \ll \eta(x)$.
  \end{itemize}
\end{lemma}

\begin{proof} \leanok
\uses{lem:integrable_fDiv_compProd_iff}
\end{proof}

\begin{lemma}
  \label{lem:fDiv_compProd_ne_top_iff}
  \lean{ProbabilityTheory.condFDiv_ne_top_iff_fDiv_compProd_ne_top}
  \leanok
  \uses{def:fDiv, def:condFDiv}
  Let $\mu$ be a finite measure on $\mathcal X$ and let $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ be two finite kernels, where $\kappa$ is a Markov kernel.
  Then $D_f(\mu \otimes \kappa, \mu \otimes \eta) \ne \infty \iff D_f(\kappa, \eta \mid \mu) \ne \infty$.
\end{lemma}

\begin{proof} \leanok
\uses{lem:integrable_fDiv_compProd_iff, lem:condFDiv_ne_top_iff}
\end{proof}

\begin{lemma}
  \label{lem:fDiv_compProd_left}
  \lean{ProbabilityTheory.fDiv_compProd_left}
  \leanok
  \uses{def:fDiv, def:condFDiv}
  Let $\mu$ be a finite measure on $\mathcal X$ and let $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ be two finite kernels.
  Then $D_f(\mu \otimes \kappa, \mu \otimes \eta) = D_f(\kappa, \eta \mid \mu)$.
\end{lemma}

\begin{proof} \leanok
\uses{cor:rnDeriv_compProd_right, cor:rnDeriv_value, lem:fDiv_compProd_ne_top_iff, lem:condFDiv_ne_top_iff}
By Lemma~\ref{lem:fDiv_compProd_ne_top_iff}, the conditions on which the two divergences are finite are the same. We then assume integrability properties such that both are finite (given by Lemma~\ref{lem:condFDiv_ne_top_iff}).

TODO: the following proof assumes $\kappa(x) \ll \eta(x)$ for $\nu$-almost all $x$. Describe the general case.

By Lemma~\ref{cor:rnDeriv_compProd_right} and Corollary~\ref{cor:rnDeriv_value},
\begin{align*}
D_f(\mu \otimes \kappa, \mu \otimes \eta)
&= \int_{p} f\left(\frac{d (\mu \otimes \kappa)}{d (\mu \otimes \eta)}(p)\right) \partial(\mu \otimes \eta)
\\
&= \int_{p} f\left(\frac{d \kappa}{d \eta}(p)\right) \partial(\mu \otimes \eta)
\\
&= \int_x \int_y f\left(\frac{d \kappa}{d \eta}(x, y)\right) \partial \eta(x) \partial \mu
\\
&= \int_x \int_y f\left(\frac{d \kappa(x)}{d \eta(x)}(y)\right) \partial \eta(x) \partial \mu
\\
&= \mu\left[D_f(\kappa(x), \eta(x))\right]
= D_f(\kappa, \eta \mid \mu)
\: .
\end{align*}
\end{proof}

\section{Data-processing inequality}

\begin{theorem}
  \label{thm:fDiv_le_compProd}
  \lean{ProbabilityTheory.le_fDiv_compProd}
  \leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two finite measures on $\mathcal X$ and let $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ be two Markov kernels.
  Then $D_f(\mu, \nu) \le D_f(\mu \otimes \kappa, \nu \otimes \eta)$.
\end{theorem}

\begin{proof}\leanok
\uses{lem:rnDeriv_compProd, cor:rnDeriv_value}
TODO: the following proof assumes $\mu \ll \nu$ and $\kappa(x) \ll \eta(x)$ for $\nu$-almost all $x$. Describe the general case.

Using Lemma~\ref{lem:rnDeriv_compProd} and \ref{cor:rnDeriv_value},
\begin{align*}
D(\mu \otimes \kappa, \nu \otimes \eta)
&= \int_x \int_y f \left( \frac{\partial \mu}{\partial\nu}(x) \frac{\partial \kappa(x)}{\partial\eta(x)}(y) \right) \partial \eta(x) \partial \nu
\: .
\end{align*}
Since $f$ is convex, by Jensen's inequality,
\begin{align*}
\int_y f \left( \frac{\partial \mu}{\partial\nu}(x) \frac{\partial \kappa(x)}{\partial\eta(x)}(y) \right) \partial \eta(x)
&\ge f \left( \int_y \frac{\partial \mu}{\partial\nu}(x) \frac{\partial \kappa(x)}{\partial\eta(x)}(y) \partial \eta(x) \right)
\\
&= f \left( \frac{\partial \mu}{\partial\nu}(x) \int_y \frac{\partial \kappa(x)}{\partial\eta(x)}(y) \partial \eta(x) \right)
\: .
\end{align*}

Since $\kappa(x) \ll \eta(x)$ for $\nu$-almost all $x$, $\int_y \frac{\partial \kappa(x)}{\partial\eta(x)}(y) \partial \eta(x) = \int_y 1 \partial \kappa(x) = 1$ a.e.. We have obtained
\begin{align*}
D_f(\mu \otimes \kappa, \nu \otimes \eta)
\ge \int_x f \left( \frac{\partial \mu}{\partial\nu}(x)\right) \partial \nu
= D_f(\mu, \nu)
\: .
\end{align*}
\end{proof}

\begin{theorem}[Marginals]
  \label{thm:fDiv_fst_le}
  \lean{ProbabilityTheory.fDiv_fst_le}
  \leanok
  \uses{def:fDiv}
  Let $\mu$ and $\nu$ be two measures on $\mathcal X \times \mathcal Y$ where $\mathcal Y$ is standard Borel, and let $\mu_X, \nu_X$ be their marginals on $\mathcal X$.
  Then $D_f(\mu_X, \nu_X) \le D_f(\mu, \nu)$.
  Similarly, for $\mathcal X$ standard Borel and $\mu_Y, \nu_Y$ the marginals on $\mathcal Y$, $D_f(\mu_Y, \nu_Y) \le D_f(\mu, \nu)$.
\end{theorem}

\begin{proof}\leanok
\uses{thm:fDiv_le_compProd, lem:fDiv_map_measurableEmbedding}
We introduce conditional kernels and write $D(\mu, \nu) = D(\mu_X \otimes \mu_{Y|X}, \nu_X \otimes \nu_{Y|X})$. Then apply Theorem~\ref{thm:fDiv_le_compProd}.
For the second statement, we need Lemma~\ref{lem:fDiv_map_measurableEmbedding} to swap the role of the two coordinates.
\end{proof}

\begin{lemma}[Composition-product with a kernel]
  \label{thm:fDiv_compProd_right}
  \lean{ProbabilityTheory.fDiv_compProd_right}
  \leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $\kappa : \mathcal X \rightsquigarrow \mathcal Y$ be a Markov kernel.
  Then $D_f(\mu \otimes \kappa, \nu \otimes \kappa) = D_f(\mu, \nu)$.
\end{lemma}

\begin{proof}\leanok
\uses{cor:rnDeriv_compProd_left}
By Corollary~\ref{cor:rnDeriv_compProd_left},
\begin{align*}
D_f(\mu \otimes \kappa, \nu \otimes \kappa)
&= \int_{p} f\left(\frac{d (\mu \otimes \kappa)}{d (\nu \otimes \kappa)}(p)\right) \partial(\nu \otimes \kappa)
\\
&= \int_{p} f\left(\frac{d \mu}{d \nu}(p_X)\right) \partial(\nu \otimes \kappa)
\\
&= \int_x \int_y f\left(\frac{d \mu}{d \nu}(x)\right) \partial \kappa(x) \partial \nu
\\
&= \int_x f\left(\frac{d \mu}{d \nu}(x)\right) \partial \nu
\\
&= D_f(\mu, \nu)
\: .
\end{align*}
\end{proof}

\begin{corollary}
  \label{cor:fDiv_prod_right}
  %\lean{}
  %\leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $\xi$ be a measure on $\mathcal Y$.
  Then $D_f(\mu \times \xi, \nu \times \xi) = D_f(\mu, \nu)$.
\end{corollary}

\begin{proof}
\uses{thm:fDiv_compProd_right}
Apply Lemma~\ref{thm:fDiv_compProd_right} with $\kappa$ the constant kernel with value $\xi$.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_comp_le_compProd}
  \lean{ProbabilityTheory.fDiv_comp_le_compProd}
  \leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two finite measures on a standard Borel space $\mathcal X$ and let $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ be two Markov kernels.
  $D_f(\kappa \circ \mu, \eta \circ \nu) \le D_f(\mu \otimes \kappa, \nu \otimes \eta)$
\end{lemma}

\begin{proof}\leanok
\uses{thm:fDiv_fst_le}
By definition, $\kappa \circ \mu$ is the marginal of $\mu \otimes \kappa$ (a measure on $\mathcal X \times \mathcal Y$) on $\mathcal Y$, and similarly for the other measure. Hence by Theorem~\ref{thm:fDiv_fst_le}, $D_f(\kappa \circ \mu, \eta \circ \nu) \le D_f(\mu \otimes \kappa, \nu \otimes \eta)$. 
\end{proof}

\begin{theorem}[Conditioning increases f-divergence]
  \label{thm:fDiv_comp_le_condFDiv}
  \lean{ProbabilityTheory.fDiv_comp_left_le}
  \leanok
  \uses{def:fDiv, def:condFDiv}
  Let $\mu$ be a measure on a standard Borel space $\mathcal X$ and let $\kappa, \eta : \mathcal X \rightsquigarrow \mathcal Y$ be two Markov kernels.
  Then $D_f(\kappa \circ \mu, \eta \circ \mu) \le D_f(\mu \otimes \kappa, \mu \otimes \eta) = D_f(\kappa, \eta \mid \mu)$
\end{theorem}

\begin{proof}\leanok
\uses{lem:fDiv_comp_le_compProd, lem:fDiv_compProd_left}
By Lemma~\ref{lem:fDiv_comp_le_compProd}, $D_f(\kappa \circ \mu, \eta \circ \mu) \le D_f(\mu \otimes \kappa, \mu \otimes \eta)$. This is equal to $D_f(\kappa, \eta \mid \mu)$ by Lemma~\ref{lem:fDiv_compProd_left}.
\end{proof}

\begin{theorem}[Data-processing]
  \label{thm:fDiv_data_proc}
  \lean{ProbabilityTheory.fDiv_comp_right_le}
  \leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $\kappa : \mathcal X \rightsquigarrow \mathcal Y$ be a Markov kernel, where both $\mathcal X$ and $\mathcal Y$ are standard Borel.
  Then $D_f(\kappa \circ \mu, \kappa \circ \nu) \le D_f(\mu, \nu)$.
\end{theorem}

\begin{proof}\leanok
\uses{lem:fDiv_comp_le_compProd, thm:fDiv_compProd_right}
By Lemma~\ref{lem:fDiv_comp_le_compProd}, $D_f(\kappa \circ \mu, \kappa \circ \nu) \le D_f(\mu \otimes \kappa, \nu \otimes \kappa)$. Then the latter is equal to $D_f(\mu, \nu)$ by Lemma~\ref{thm:fDiv_compProd_right}.
\end{proof}


\begin{corollary}
  \label{cor:data_proc_event}
  %\lean{}
  %\leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $E$ be an event. Let $\mu_E$ and $\nu_E$ be the two Bernoulli distributions with respective means $\mu(E)$ and $\nu(E)$. Then $D_f(\mu, \nu) \ge D_f(\mu_E, \nu_E)$.
\end{corollary}

\begin{proof}
\uses{thm:fDiv_data_proc}
Use the deterministic kernel $\kappa : \mathcal X \rightsquigarrow \{0, 1\}$ with $\kappa(x) = \delta_1 \mathbb{I}\{x \in E\} + \delta_0 \mathbb{I}\{x \notin E\}$ in Theorem~\ref{thm:fDiv_data_proc}.
\end{proof}

\begin{lemma}
  \label{lem:fDiv_compProd_prod_eq}
  %\lean{}
  %\leanok
  \uses{def:fDiv}
  Let $\mu, \nu$ be two measures on $\mathcal X$ and let $\kappa : \mathcal X \rightsquigarrow (\mathcal X \times \mathcal Y)$ be a Markov kernel such that for all $x$, $(\kappa(x))_X = \delta_x$. Then $D_f(\kappa \circ \mu, \kappa \circ \nu) = D_f(\mu, \nu)$.
\end{lemma}

\begin{proof}
\uses{thm:fDiv_data_proc, thm:fDiv_fst_le}
$D_f(\kappa \circ \mu, \kappa \circ \nu) \le D_f(\mu, \nu)$ by Theorem~\ref{thm:fDiv_data_proc}.
For the other inequality, remark that $\mu = (\kappa \circ \mu)_X$ (and similarly for $\nu$). Hence by Theorem~\ref{thm:fDiv_fst_le} $D_f(\mu, \nu) \le D_f(\kappa \circ \mu, \kappa \circ \nu)$.
\end{proof}

\section{Convexity}

\begin{theorem}[Joint convexity]
  \label{thm:fDiv_convex}
  %\lean{}
  %\leanok
  \uses{def:fDiv}
  The function $(\mu, \nu) \mapsto D_f(\mu, \nu)$ is convex.
\end{theorem}

\begin{proof}
\uses{thm:fDiv_comp_le_condFDiv}
Let $\mu_0, \mu_1, \nu_0, \nu_1$ be four measures. Let $\lambda \in [0,1]$. Let $\xi$ be the probability measure on $\{0,1\}$ with $\xi(\{1\}) = \lambda$.
Let $\kappa$ be the kernel $\{0,1\} \rightsquigarrow \mathcal X$ defined by $\kappa(0) = \mu_0$ and $\kappa(1) = \mu_1$.
Let $\eta$ be the kernel $\{0,1\} \rightsquigarrow \mathcal X$ defined by $\eta(0) = \nu_0$ and $\eta(1) = \nu_1$.
\begin{align*}
D_f(\xi \otimes \kappa, \xi \otimes \eta)
&= D_f(\kappa, \eta \mid \xi)
= (1 - \lambda) D_f(\mu_0, \nu_0) + \lambda D_f(\mu_1, \nu_1)
\: , \\
D_f(\kappa \circ \xi, \eta \circ \xi)
&= D_f((1 - \lambda)\mu_0 + \lambda \mu_1, (1 - \lambda)\nu_0 + \lambda \nu_1)
\: .
\end{align*}
By Theorem~\ref{thm:fDiv_comp_le_condFDiv}, $D_f(\kappa \circ \xi, \eta \circ \xi) \le D_f(\xi \otimes \kappa, \xi \otimes \eta)$.
\end{proof}

\section{Variational representations}

TODO