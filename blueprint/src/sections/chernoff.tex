\section{Chernoff divergence}

\begin{definition}[Chernoff divergence]
  \label{def:Chernoff}
  \lean{ProbabilityTheory.chernoffDiv}
  \leanok
  \uses{def:Renyi}
    The Chernoff divergence of order $\alpha > 0$ between two measures $\mu$ and $\nu$ on $\mathcal X$ is
  \begin{align*}
    C_\alpha(\mu, \nu) = \inf_{\xi \in \mathcal P(\mathcal X)}\max\{R_\alpha(\xi, \mu), R_\alpha(\xi, \nu)\} \: .
  \end{align*}
\end{definition}

Note: the name Chernoff divergence is usually reserved for $C_1$, and any reference to $C$ without subscript in this document refers to $C_1$.
The extension to other orders $\alpha$ is motivated by the appearance of $C_\alpha$ in a result further down.
This is not a well established notion and it remains to see if this extension is meaningful.

\begin{lemma}
  \label{lem:chernoff_eq_kl}
  \lean{ProbabilityTheory.chernoffDiv_one}
  \leanok
  \uses{def:Chernoff, def:KL}
  $C_1(\mu, \nu) = \inf_{\xi \in \mathcal P(\mathcal X)}\max\{\KL(\xi, \mu), \KL(\xi, \nu)\}$ .
\end{lemma}

\begin{proof}\leanok
\uses{def:Renyi}
This is $R_1 = \KL$ (by definition).
\end{proof}

\begin{lemma}[Symmetry]
  \label{lem:chernoff_symm}
  %\lean{}
  %\leanok
  \uses{def:Chernoff}
  $C_\alpha(\mu, \nu) = C_\alpha(\nu, \mu)$.
\end{lemma}

\begin{proof}%\leanok
Immediate from the definition.
\end{proof}

\begin{lemma}[Monotonicity]
  \label{lem:chernoff_mono}
  %\lean{}
  %\leanok
  \uses{def:Chernoff}
  The function $\alpha \mapsto C_\alpha(\mu, \nu)$ is monotone.
\end{lemma}

\begin{proof}
\uses{lem:renyi_monotone}
Consequence of Lemma~\ref{lem:renyi_monotone}.
\end{proof}

\begin{lemma}
  \label{lem:chernoff_eq_max_renyi}
  %\lean{}
  %\leanok
  \uses{def:Chernoff, def:Renyi}
  \begin{align*}
  C_1(\mu, \nu) = \max_{\alpha\in [0,1]} (1 - \alpha)R_\alpha(\mu, \nu) \: .
  \end{align*}
\end{lemma}

\begin{proof}%\leanok
\uses{}
\end{proof}


\begin{lemma}
  \label{lem:bayesBinaryRisk_eq_exp_renyi_mul_integral}
  %\lean{}
  %\leanok
  \uses{def:bayesBinaryRisk, def:Renyi, def:renyiMeasure}
  Let $\zeta$ be a measure such that $\mu \ll \zeta$ and $\nu \ll \zeta$. Let $p = \frac{d \mu}{d\zeta}$ and $q = \frac{d \nu}{d\zeta}$.
  For $\alpha \in (0,1)$, for $g_\alpha(x) = \min\{(\alpha-1)x, \alpha x\}$,
  \begin{align*}
  \mathcal B_\xi(\mu, \nu)
  = e^{-(1 - \alpha) R_\alpha(\xi_0\mu, \xi_1\nu)} \int_x \exp \left(g_\alpha\left( \log \frac{\xi_1 q(x)}{\xi_0 p(x)} \right)\right) \partial(\xi_0\mu)^{(\alpha, \xi_1\nu)}
  \: .
  \end{align*}
\end{lemma}

\begin{proof}%\leanok
\uses{thm:bayesBinaryRisk_eq}
\begin{align*}
\mathcal B_\xi(\mu, \nu)
&= \int_x \min \left\{\xi_0 p(x), \xi_1 q(x)\right\} \partial\zeta
\\
&= \int_x (\xi_0 p(x))^\alpha (\xi_1 q(x))^{1-\alpha} \min \left\{ \left(\frac{\xi_0p(x)}{\xi_1q(x)}\right)^{1 - \alpha}, \left(\frac{\xi_1q(x)}{\xi_0p(x)}\right)^\alpha\right\} \partial\zeta
\\
&= e^{-(1 - \alpha) R_\alpha(\xi_0\mu, \xi_1\nu)} \int_x \min \left\{ \left(\frac{\xi_1q(x)}{\xi_0p(x)}\right)^{\alpha - 1}, \left(\frac{\xi_1q(x)}{\xi_0p(x)}\right)^\alpha\right\} \partial(\xi_0\mu)^{(\alpha, \xi_1\nu)}
\: .
\end{align*}
\end{proof}


\begin{corollary}
  \label{cor:bayesBinaryRisk_le_exp_renyi}
  %\lean{}
  %\leanok
  \uses{def:bayesBinaryRisk, def:Renyi}
  For $\alpha \in (0,1)$,
  \begin{align*}
  \mathcal B_\xi(\mu, \nu)
  \le e^{-(1 - \alpha) R_\alpha(\xi_0\mu, \xi_1\nu)}
  = \xi_0^\alpha \xi_1^{1-\alpha} e^{-(1 - \alpha) R_\alpha(\mu, \nu)}
  \: .
  \end{align*}
\end{corollary}

\begin{proof}%\leanok
\uses{lem:bayesBinaryRisk_eq_exp_renyi_mul_integral}
Use $g_\alpha(x) \le 0$ in Lemma~\ref{lem:bayesBinaryRisk_eq_exp_renyi_mul_integral}.
\end{proof}


\begin{lemma}
  \label{lem:bayesBinaryRisk_le_exp_chernoff}
  %\lean{}
  %\leanok
  \uses{def:bayesBinaryRisk, def:Chernoff}
  For $\alpha \in (0,1)$,
  \begin{align*}
  \mathcal B_\xi(\mu, \nu)
  \le e^{- C_1(\xi_0\mu, \xi_1\nu)}
  \: .
  \end{align*}
\end{lemma}

\begin{proof}%\leanok
\uses{cor:bayesBinaryRisk_le_exp_renyi, lem:chernoff_eq_max_renyi}
Optimize over $\alpha$ in Corollary~\ref{cor:bayesBinaryRisk_le_exp_renyi}: the optimal value gives the Chernoff information thanks to Lemma~\ref{lem:chernoff_eq_max_renyi}.
\end{proof}


\begin{lemma}
  \label{lem:one_sub_tv_le_exp_chernoff}
  %\lean{}
  %\leanok
  \uses{def:TV, def:Chernoff}
  For probability measures,
  \begin{align*}
  1 - \TV(\mu, \nu) \le e^{- C_1(\mu, \nu)} \: .
  \end{align*}
\end{lemma}

\begin{proof}%\leanok
\uses{lem:bayesBinaryRisk_le_exp_chernoff}
By definition, since $\mu$ and $\nu$ are probability measures, $1 - \TV(\mu, \nu) = \mathcal B_{(1,1)}(\mu, \nu)$. Then apply Lemma~\ref{lem:bayesBinaryRisk_le_exp_chernoff}.
\end{proof}