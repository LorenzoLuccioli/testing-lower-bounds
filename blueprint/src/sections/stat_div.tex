A divergence between measures is a function which maps two measures on any common space $\mathcal X$ to a value in $[-\infty, +\infty]$.
For two probability measures $\mu$ and $\nu$, we will want the divergence $D(\mu, \nu)$ to be non-negative and to be zero if $\mu = \nu$~: divergences are meant to be notions of dissimilarity between measures.

\section{Statistical divergences}

\begin{definition}
  \label{def:statInfo}
  %\lean{}
  %\leanok
  \uses{def:bayesBinaryRisk, def:riskIncrease}
  The statistical information between measures $\mu$ and $\nu$ with respect to prior $\xi \in \mathcal M(\{0,1\})$ is
  $\mathcal I_\xi(\mu, \nu) = \min\{\xi_0 \mu(\mathcal X), \xi_1 \nu(\mathcal X)\} - \mathcal B_\xi(\mu, \nu)$.
  This is the risk increase $I_\xi^P(d_{\mathcal X})$ in the binary hypothesis testing problem for $d_{\mathcal X} : \mathcal X \rightsquigarrow *$ the Markov kernel to the point space.
\end{definition}

The statistical information is the difference between the minimal risk of an estimator that does not depend on the data and that of a Bayes estimator.
This is a simple generalization of both the DeGroot statistical information as well as the hockey-stick (or $E_\gamma$) divergence.

\begin{lemma}
  \label{lem:statInfo_self}
  %\lean{}
  %\leanok
  \uses{def:statInfo}
  For $\mu \in \mathcal M(\mathcal X)$, $\mathcal I_\xi(\mu, \mu) = 0$~.
\end{lemma}

\begin{proof}%\leanok
\uses{lem:bayesBinaryRisk_self}
Use Lemma~\ref{lem:bayesBinaryRisk_self}.
\end{proof}

\begin{lemma}
  \label{lem:statInfo_nonneg}
  %\lean{}
  %\leanok
  \uses{def:statInfo}
  For $\mu, \nu \in \mathcal M(\mathcal X)$, $\mathcal I_\xi(\mu, \nu) \ge 0$~.
\end{lemma}

\begin{proof}%\leanok
\uses{lem:bayesBinaryRisk_le}
Use Lemma~\ref{lem:bayesBinaryRisk_le}.
\end{proof}

\begin{lemma}
  \label{lem:statInfo_symm}
  %\lean{}
  %\leanok
  \uses{def:statInfo}
  For $\mu, \nu \in \mathcal M(\mathcal X)$ and $\xi \in \mathcal M(\{0,1\})$, $\mathcal I_\xi(\mu, \nu) = \mathcal I_{\xi_\leftrightarrow}(\nu, \mu)$~.
\end{lemma}

\begin{proof}%\leanok
\uses{lem:bayesBinaryRisk_symm}
Use Lemma~\ref{lem:bayesBinaryRisk_symm}.
\end{proof}

\begin{theorem}[Data-processing inequality]
  \label{thm:data_proc_statInfo}
  %\lean{ProbabilityTheory.}
  %\leanok
  \uses{def:statInfo}
  For $\mu, \nu \in \mathcal M(\mathcal X)$, $\xi \in \mathcal M(\{0,1\})$ and $\kappa : \mathcal X \rightsquigarrow \mathcal Y$ a Markov kernel, $\mathcal I_\xi(\kappa \circ \mu, \kappa \circ \nu) \le \mathcal I_\xi(\mu, \nu)$~.
\end{theorem}

\begin{proof}%\leanok
\uses{thm:data_proc_bayesBinaryRisk, lem:riskIncrease_comp_del}
Since $\kappa$ is a Markov kernel,
\begin{align*}
\mathcal I_\xi(\kappa \circ \mu, \kappa \circ \nu)
&= \min\{\xi_0(\kappa \circ \mu)(\mathcal X), \xi_1(\kappa \circ \nu)(\mathcal X)\} - \mathcal B_\xi(\kappa \circ \mu, \kappa \circ \nu)
\\
&= \min\{\xi_0 \mu(\mathcal X), \xi_1 \nu(\mathcal X)\} - \mathcal B_\xi(\kappa \circ \mu, \kappa \circ \nu)
\end{align*}
It suffices to prove $\mathcal B_\xi(\kappa \circ \mu, \kappa \circ \nu) \ge \mathcal B_\xi(\mu, \nu)$ since $\mathcal I_\xi(\mu, \nu) = \min\{\xi_0\mu(\mathcal X), \xi_1\nu(\mathcal X)\} - \mathcal B_\xi(\mu, \nu)$.
The inequality was proved in Theorem~\ref{thm:data_proc_bayesBinaryRisk}.

Alternatively, we can use Lemma~\ref{lem:riskIncrease_comp_del}.
\end{proof}

\begin{theorem}[Integral form of the statistical information]
  \label{thm:statInfo_eq_integral}
  %\lean{}
  %\leanok
  \uses{def:statInfo}
  For finite measures $\mu, \nu$ and $\xi \in \mathcal M(\{0,1\})$,
  \begin{align*}
  \mathcal I_\xi(\mu, \nu)
  &= \nu\left[ x \mapsto \max \left\{0 , \xi_0\frac{d \mu}{d\nu}(x) - \xi_1 \right\} \right] + \xi_0 \mu_{\perp \nu}(\mathcal X) & \text{ if } \xi_0 \mu(\mathcal X) \le \xi_1 \nu(\mathcal X)
  \: , \\
  \mathcal I_\xi(\mu, \nu)
  &= \nu\left[ x \mapsto \max \left\{0 , \xi_1 - \xi_0\frac{d \mu}{d\nu}(x) \right\} \right] & \text{ if } \xi_0 \mu(\mathcal X) \ge \xi_1 \nu(\mathcal X)
  \: .
  \end{align*}
  
\end{theorem}

For probability measures, this theorem makes the statistical information an $f$-divergence (which is defined later in this document).

\begin{proof}%\leanok
\uses{thm:bayesBinaryRisk_eq}
By Theorem~\ref{thm:bayesBinaryRisk_eq},
\begin{align*}
\mathcal I_\xi(\mu, \nu)
&= \min\{\xi_0\mu(\mathcal X), \xi_1\nu(\mathcal X)\} - (P \circ \xi)\left[x \mapsto \min \left\{\xi_0\frac{d \mu}{d(P \circ \xi)}(x), \xi_1\frac{d \nu}{d(P \circ \xi)}(x)\right\}\right]
\: .
\end{align*}
Suppose that $\xi_0\mu(\mathcal X) \le \xi_1\nu(\mathcal X)$~. Then
\begin{align*}
\mathcal I_\xi(\mu, \nu)
&= \xi_0\mu(\mathcal X) - (P \circ \xi)\left[x \mapsto \xi_0\frac{d \mu}{d(P \circ \xi)}(x) + \min \left\{0 , \xi_1\frac{d \nu}{d(P \circ \xi)}(x) - \xi_0\frac{d \mu}{d(P \circ \xi)}(x)\right\}\right]
\\
&= - (P \circ \xi)\left[x \mapsto \min \left\{0 , \xi_1\frac{d \nu}{d(P \circ \xi)}(x) - \xi_0\frac{d \mu}{d(P \circ \xi)}(x) \right\}\right]
\\
&= (P \circ \xi)\left[x \mapsto \max \left\{0 , \xi_0\frac{d \mu}{d(P \circ \xi)}(x) - \xi_1\frac{d \nu}{d(P \circ \xi)}(x) \right\}\right]
\\
&= \nu\left[ x \mapsto \max \left\{0 , \xi_0\frac{d \mu}{d\nu}(x) - \xi_1 \right\} \right] + \xi_0 \mu_{\perp \nu}(\mathcal X)
\: .
\end{align*}
If on the other hand $\xi_0\mu(\mathcal X) \ge \xi_1\nu(\mathcal X)$~, with similar computations,
\begin{align*}
\mathcal I_\xi(\mu, \nu)
&= (P \circ \xi)\left[x \mapsto \max \left\{0 , \xi_1\frac{d \nu}{d(P \circ \xi)}(x) - \xi_0\frac{d \mu}{d(P \circ \xi)}(x) \right\}\right]
\\
&= \nu\left[ x \mapsto \max \left\{0 , \xi_1 - \xi_0\frac{d \mu}{d\nu}(x) \right\} \right]
\: .
\end{align*}
\end{proof}


\subsection{DeGroot statistical information}

TODO: we could also call the more general statistical information defined above the DeGroot statistical information.

\begin{definition}
  \label{def:deGrootInfo}
  \lean{ProbabilityTheory.deGrootInfo}
  \leanok
  \uses{def:statInfo}
  The DeGroot statistical information between finite measures $\mu$ and $\nu$ for $\pi \in [0,1]$ is $I_\pi(\mu, \nu) = \mathcal I_{(\pi, 1 - \pi)}(\mu, \nu)$~.
\end{definition}

\begin{lemma}
  \label{lem:deGrootInfo_self}
  %\lean{}
  %\leanok
  \uses{def:deGrootInfo}
  For $\mu \in \mathcal M(\mathcal X)$, $I_\pi(\mu, \mu) = 0$~.
\end{lemma}

\begin{proof}%\leanok
\uses{lem:statInfo_self}
Use Lemma~\ref{lem:statInfo_self}.
\end{proof}

\begin{lemma}
  \label{lem:deGrootInfo_nonneg}
  %\lean{}
  %\leanok
  \uses{def:deGrootInfo}
  For $\mu, \nu \in \mathcal M(\mathcal X)$, $I_\pi(\mu, \nu) \ge 0$~.
\end{lemma}

\begin{proof}%\leanok
\uses{lem:statInfo_nonneg}
Use Lemma~\ref{lem:statInfo_nonneg}.
\end{proof}

\begin{lemma}
  \label{lem:deGrootInfo_symm}
  %\lean{}
  %\leanok
  \uses{def:deGrootInfo}
  For $\mu, \nu \in \mathcal M(\mathcal X)$ and $\pi \in [0,1]$, $I_\pi(\mu, \nu) = I_{1 - \pi}(\nu, \mu)$~.
\end{lemma}

\begin{proof}%\leanok
\uses{lem:statInfo_symm}
Use Lemma~\ref{lem:statInfo_symm}.
\end{proof}

\begin{theorem}[Data-processing inequality]
  \label{thm:data_proc_deGrootInfo}
  \lean{ProbabilityTheory.deGrootInfo_comp_le}
  \leanok
  \uses{def:deGrootInfo}
  For $\mu, \nu \in \mathcal M(\mathcal X)$ and $\kappa : \mathcal X \rightsquigarrow \mathcal Y$ a Markov kernel, $I_\pi(\kappa \circ \mu, \kappa \circ \nu) \le I_\pi(\mu, \nu)$~.
\end{theorem}

\begin{proof}\leanok
\uses{thm:data_proc_statInfo}
Apply Theorem~\ref{thm:data_proc_statInfo}.
\end{proof}


\begin{lemma}[Integral form of the DeGroot statistical information]
  \label{lem:deGrootInfo_eq_integral}
  %\lean{}
  %\leanok
  \uses{def:deGrootInfo}
  For finite measures $\mu, \nu$ and $\pi \in [0,1]$,
  \begin{align*}
  I_\pi(\mu, \nu)
  &= \nu\left[ x \mapsto \pi \max \left\{0 , \frac{d \mu}{d\nu}(x) - \frac{1 - \pi}{\pi} \right\} \right] + \pi \mu_{\perp \nu}(\mathcal X) & \text{ if } \pi \mu(\mathcal X) \le (1 - \pi) \nu(\mathcal X)
  \: , \\
  I_\pi(\mu, \nu)
  &= \nu\left[ x \mapsto \pi \max \left\{0 , \frac{1 - \pi}{\pi} - \frac{d \mu}{d\nu}(x) \right\} \right] & \text{ if } \pi \mu(\mathcal X) \ge (1 - \pi) \nu(\mathcal X)
  \: .
  \end{align*}
\end{lemma}

\begin{proof}%\leanok
\uses{thm:statInfo_eq_integral}
Apply Theorem~\ref{thm:statInfo_eq_integral}.
\end{proof}

\subsection{Hockey-stick divergence}


\begin{definition}
  \label{def:eGamma}
  %\lean{}
  %\leanok
  \uses{def:statInfo}
  The $E_\gamma$ or hockey-stick divergence between finite measures $\mu$ and $\nu$ for $\gamma \in (0,+\infty)$ is $E_\gamma(\mu, \nu) = \mathcal I_{(1,\gamma)}(\mu, \nu)$~.
\end{definition}

Note that our definition of the $E_\gamma$ divergence extends the one from the literature: the divergence is usually defined for $\gamma \ge 1$ only.
The extension makes sense in light of Theorem~\ref{thm:fDiv_eq_integral_eGamma}.
It is also extended from probability measures to finite measures.

\begin{lemma}
  \label{lem:eGamma_self}
  %\lean{}
  %\leanok
  \uses{def:eGamma}
  For $\mu \in \mathcal M(\mathcal X)$, $E_\gamma(\mu, \mu) = 0$~.
\end{lemma}

\begin{proof}%\leanok
\uses{lem:statInfo_self}
Use Lemma~\ref{lem:statInfo_self}.
\end{proof}

\begin{lemma}
  \label{lem:eGamma_nonneg}
  %\lean{}
  %\leanok
  \uses{def:eGamma}
  For $\mu, \nu \in \mathcal M(\mathcal X)$, $E_\gamma(\mu, \nu) \ge 0$~.
\end{lemma}

\begin{proof}%\leanok
\uses{lem:statInfo_nonneg}
Use Lemma~\ref{lem:statInfo_nonneg}.
\end{proof}

\begin{theorem}[Data-processing inequality]
  \label{thm:data_proc_eGamma}
  %\lean{ProbabilityTheory.}
  %\leanok
  \uses{def:eGamma}
  For $\mu, \nu \in \mathcal M(\mathcal X)$ and $\kappa : \mathcal X \rightsquigarrow \mathcal Y$ a Markov kernel, $E_\gamma(\kappa \circ \mu, \kappa \circ \nu) \le E_\gamma(\mu, \nu)$~.
\end{theorem}

\begin{proof}%\leanok
\uses{thm:data_proc_statInfo}
Apply Theorem~\ref{thm:data_proc_statInfo}.
\end{proof}

\begin{lemma}[Integral form of the hockey-stick divergence]
  \label{lem:eGamma_eq_integral}
  %\lean{}
  %\leanok
  \uses{def:eGamma}
  For finite measures $\mu, \nu$ and $\gamma \in (0,+\infty)$,
  \begin{align*}
  E_\gamma(\mu, \nu)
  &= \nu\left[ x \mapsto \max \left\{0 , \frac{d \mu}{d\nu}(x) - \gamma \right\} \right] + \mu_{\perp \nu}(\mathcal X) & \text{ if } \mu(\mathcal X) \le \gamma \nu(\mathcal X)
  \: , \\
  E_\gamma(\mu, \nu)
  &= \nu\left[ x \mapsto \max \left\{0 , \gamma - \frac{d \mu}{d\nu}(x) \right\} \right] & \text{ if } \mu(\mathcal X) \ge \gamma \nu(\mathcal X)
  \: .
  \end{align*}
\end{lemma}

\begin{proof}%\leanok
\uses{thm:statInfo_eq_integral}
Apply Theorem~\ref{thm:statInfo_eq_integral}.
\end{proof}